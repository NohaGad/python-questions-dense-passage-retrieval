{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qzo8GkZ6bqx",
        "outputId": "c3de7b06-51b5-479e-8927-c0b104d1b207"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 48.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 49.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Installing collected packages: huggingface-hub, sacremoses, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUM1re8sP04j"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModel,AdamW,get_linear_schedule_with_warmup\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler,TensorDataset,Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JzPRP3PRiEz",
        "outputId": "170fc426-ce31-4e33-d6ec-2ea05cdd23d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ]
        }
      ],
      "source": [
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkSQTu7Ypit0"
      },
      "source": [
        "**We** first split the data into a train and validation and test set. The test set will be used later to evaluate our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BicIsQ_g-nGY",
        "outputId": "13b13fd2-1a2c-4456-ce09-a7848835bea0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Kaggle/stackoverflow/final\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Kaggle/stackoverflow/final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGF6XnXE7sAJ",
        "outputId": "fa3ebb87-74c9-499f-a908-e4e40d5d7e76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of train: 1626900, length of validation: 24776, length of test: 16684\n"
          ]
        }
      ],
      "source": [
        "# df = pd.read_pickle(\"../big_dataset.pkl\")\n",
        "# df = df.reset_index(drop=True)\n",
        "# train_dataset,test_dataset = train_test_split(df, test_size=0.01,stratify = df[\"is_answer\"])\n",
        "# train_dataset,val_dataset = train_test_split(train_dataset, test_size=0.015,stratify = train_dataset[\"is_answer\"])\n",
        "# print(f\"length of train: {len(train_dataset)}, length of validation: {len(val_dataset)}, length of test: {len(test_dataset)}\")\n",
        "# del df #to reduce memory usage\n",
        "# pd.to_pickle(train_dataset,\"train_ds_big.pkl\")\n",
        "# pd.to_pickle(val_dataset,\"val_ds_big.pkl\")\n",
        "# pd.to_pickle(test_dataset,\"test_ds_big.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5U6ZyU2GQAgZ",
        "outputId": "a27ea3ba-bfd1-4ba6-8417-75226a1fb785"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of train: 1618683, length of validation: 24651, length of test: 25026\n"
          ]
        }
      ],
      "source": [
        "train_dataset = pd.read_pickle(\"train_ds_big.pkl\")\n",
        "val_dataset = pd.read_pickle(\"val_ds_big.pkl\")\n",
        "test_dataset = pd.read_pickle(\"test_ds_big.pkl\")\n",
        "print(f\"length of train: {len(train_dataset)}, length of validation: {len(val_dataset)}, length of test: {len(test_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuyDIxLwcRGX"
      },
      "source": [
        "**We**  select only the question pairs that have answers to train the model. <br>\n",
        "We build two batches as input for the network and we assume that question $q_i$ (question $i$ in the first batch) is a answer of $a_i$ (answer $i$ in the second batch), but all other answers in the second batch are not answers of $q_i$.  \n",
        "The test set uses the original pairs of questions and the status describing if the answers are answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsthnEy7_c6K",
        "outputId": "5e7b9043-8dce-4b76-a9ee-8a1480d77df3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of postive examples in train dataset: 809341\n",
            "length of postive examples in validation dataset: 12326\n",
            "length of postive examples in validation dataset: 12513\n"
          ]
        }
      ],
      "source": [
        "train_dataset = train_dataset[train_dataset[\"is_answer\"]==1]\n",
        "print(f\"length of postive examples in train dataset: {len(train_dataset)}\")\n",
        "val_dataset = val_dataset[val_dataset[\"is_answer\"]==1]\n",
        "print(f\"length of postive examples in validation dataset: {len(val_dataset)}\")\n",
        "test_dataset = test_dataset[test_dataset[\"is_answer\"]==1]\n",
        "print(f\"length of postive examples in validation dataset: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOEv5RSEbcba"
      },
      "outputs": [],
      "source": [
        "class QADataset(Dataset):\n",
        "\n",
        "    def __init__(self,df):\n",
        "        \n",
        "        self.ques_title = df[\"ques_title\"].to_numpy()\n",
        "        self.ques_body = df[\"ques_body\"].to_numpy()\n",
        "        self.ans = df[\"ans\"].to_numpy()\n",
        "        self.label = df[\"is_answer\"].to_numpy()\n",
        "        \n",
        "        \n",
        "\n",
        "    # support indexing such that dataset[i] can be used to get i-th sample\n",
        "    def __getitem__(self, index):\n",
        "        return { \n",
        "            \"ques_title\":self.ques_title[index],\n",
        "            \"ques_body\":self.ques_body[index],\n",
        "            \"ans\":self.ans[index],\n",
        "            \"label\":self.label[index]\n",
        "        }\n",
        "\n",
        "    # we can call len(dataset) to return the size\n",
        "    def __len__(self):\n",
        "        return len(self.ans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQ4hiWE5vyfp"
      },
      "outputs": [],
      "source": [
        "model_name=\"distilbert-base-uncased\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEMO8KvQjCB0"
      },
      "outputs": [],
      "source": [
        "class BertEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BertOverflowEncoder, self).__init__()\n",
        "        self.bert = AutoModel.from_pretrained(model_name)\n",
        "        \n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_state = output[0]  # (bs, seq_len, dim)\n",
        "        pooled_output = hidden_state[:, 0]  # (bs, dim)\n",
        "\n",
        "        return pooled_output\n",
        "\n",
        "class DPR(nn.Module):\n",
        "    def __init__(self,question_encoder,answer_encoder):\n",
        "          super(DPR, self).__init__()\n",
        "          self.question_encoder = question_encoder\n",
        "          self.answer_encoder = answer_encoder\n",
        "\n",
        "    def forward(self, ques_ids, ques_mask, ans_ids, ans_mask):\n",
        "        ques_encoding = self.question_encoder(input_ids=ques_ids, attention_mask=ques_mask)\n",
        "        ans_encoding = self.answer_encoder(input_ids=ans_ids, attention_mask=ans_mask)\n",
        "\n",
        "        return ques_encoding,ans_encoding\n",
        "\n",
        "def negative_log_loss(q_vectors,ctx_vectors,loss_scale=None):\n",
        "        \"\"\"\n",
        "        Computes nll loss for the given lists of question and ctx vectors.\n",
        "        :return: a tuple of loss value and amount of correct predictions per batch\n",
        "        \"\"\"\n",
        "        # q_vector: n1 x D, ctx_vectors: n2 x D, result n1 x n2\n",
        "        \n",
        "        scores = torch.matmul(q_vectors, torch.transpose(ctx_vectors, 0, 1))\n",
        "\n",
        "        if len(q_vectors.size()) > 1:\n",
        "            q_num = q_vectors.size(0)\n",
        "            scores = scores.view(q_num, -1)\n",
        "\n",
        "        softmax_scores = nn.functional.log_softmax(scores, dim=1)\n",
        "        labels = torch.tensor(range(len(scores)), dtype=torch.long, device=device)\n",
        "\n",
        "        loss = nn.functional.nll_loss(\n",
        "            softmax_scores,\n",
        "            labels,\n",
        "            reduction=\"mean\",\n",
        "        )\n",
        "\n",
        "        max_score, max_idxs = torch.max(softmax_scores, 1)\n",
        "        correct_predictions_count = (max_idxs == labels).to(max_idxs.device).sum()\n",
        "\n",
        "        if loss_scale:\n",
        "            loss.mul_(loss_scale)\n",
        "\n",
        "        return loss, correct_predictions_count.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WMGCVs9GssV"
      },
      "outputs": [],
      "source": [
        "save_counter = 0\n",
        "def save_best(model):\n",
        "    torch.save(model.state_dict(), 'best_model_state_dot.bin')\n",
        "\n",
        "def save_recent(model,history,best_loss):\n",
        "    global save_counter\n",
        "    print(f\"Saved at {datetime.now().strftime('%H:%M:%S')}\")\n",
        "    context= {\n",
        "        \"history\": history,\n",
        "        \"best_loss\":best_loss\n",
        "        }\n",
        "    pd.to_pickle(context,\"context_dot.pkl\")\n",
        "    torch.save(model.state_dict(), f'recent_model_state{save_counter}_dot.bin')\n",
        "    save_counter = 1- save_counter\n",
        "\n",
        "def load():\n",
        "    context = pd.read_pickle(\"context_dot.pkl\")\n",
        "    best_state = torch.load('recent_model_state1_dot.bin');\n",
        "    return best_state,context\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDLuYY4MoG-S"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "adam_eps =  1e-8\n",
        "adam_betas =  (0.9, 0.999)\n",
        "max_grad_norm =  1.0\n",
        "small_batches_step = 100\n",
        "big_batches_step = 200\n",
        "weight_decay = 0.0\n",
        "learning_rate =  1e-5\n",
        "\n",
        "# Linear warmup over warmup_steps.\n",
        "warmup_steps = 1200 #prev 1000\n",
        "\n",
        "# Total number of training epochs to perform.\n",
        "num_train_epochs=  4\n",
        "\n",
        "#BERT\n",
        "ques_max_length=256\n",
        "ans_max_length= 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwNoAnR3DDvL"
      },
      "outputs": [],
      "source": [
        "train_data_loader = DataLoader(QADataset(train_dataset),batch_size=batch_size,shuffle=True)\n",
        "val_data_loader = DataLoader(QADataset(val_dataset),batch_size=batch_size)\n",
        "test_data_loader = DataLoader(QADataset(test_dataset),batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrKo5gBaDGV8"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0e731b6f773e435fa68f71f0a5b13f92",
            "575ac7fb8c794006a9afc34867ece5f4",
            "a91a2d21aabc4b44b02dbdeecaa81672",
            "f3800d9af1a6447cac954cdc0b270951",
            "cc18683023bf4c089c9274f0874d826b",
            "7003e0810c2147ca9c7a3fbf4fa58594",
            "789bcaec8ddb44d3b5bb32d92b6363f1",
            "df737e446eee4f9faaed72f1d0975385"
          ]
        },
        "id": "ipopIuUyhj4Q",
        "outputId": "a9caaf2d-2998-4914-b2de-ca0ef138ad07"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e731b6f773e435fa68f71f0a5b13f92",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267967963.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DPR(\n",
              "  (question_encoder): BertOverflowEncoder(\n",
              "    (bert): DistilBertModel(\n",
              "      (embeddings): Embeddings(\n",
              "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (transformer): Transformer(\n",
              "        (layer): ModuleList(\n",
              "          (0): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (1): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (2): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (3): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (4): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (5): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (answer_encoder): BertOverflowEncoder(\n",
              "    (bert): DistilBertModel(\n",
              "      (embeddings): Embeddings(\n",
              "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (transformer): Transformer(\n",
              "        (layer): ModuleList(\n",
              "          (0): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (1): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (2): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (3): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (4): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "          (5): TransformerBlock(\n",
              "            (attention): MultiHeadSelfAttention(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (ffn): FFN(\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            )\n",
              "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 15,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ques_encoder_model = BertOverflowEncoder()\n",
        "ans_encoder_model = BertOverflowEncoder()\n",
        "model = DPR(ques_encoder_model,ans_encoder_model)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCCeAdauDLEx"
      },
      "outputs": [],
      "source": [
        "optimizer = AdamW(model.parameters(), lr=learning_rate,weight_decay=weight_decay, eps=adam_eps,betas=adam_betas)\n",
        "\n",
        "total_steps = len(train_data_loader) * num_train_epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=warmup_steps,\n",
        "  num_training_steps=total_steps\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNq-61EuIvn_"
      },
      "outputs": [],
      "source": [
        "history = defaultdict(list)\n",
        "best_loss =1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3F2TIPpCA1w",
        "outputId": "59ddb6a6-254f-417d-f13d-3197d12de806"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 27,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# # load last state\n",
        "# last_state, context = load()\n",
        "# history,best_loss = context[\"history\"],context[\"best_loss\"]\n",
        "# model.load_state_dict(last_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RG0RmNvb6njH"
      },
      "outputs": [],
      "source": [
        "def eval_model( model, data_loader, loss_fn):\n",
        "    losses = []\n",
        "    accuracy = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(data_loader):\n",
        "            \n",
        "            ques_title_batch, ques_body_batch, ans_batch = batch[\"ques_title\"], batch['ques_body'], batch[\"ans\"]      \n",
        "            ques_encoding =tokenizer.__call__(\n",
        "                ques_title_batch,\n",
        "                text_pair = ques_body_batch,\n",
        "                truncation=True,\n",
        "                max_length=ques_max_length,\n",
        "                padding='longest',\n",
        "                return_tensors = 'pt'\n",
        "            )  \n",
        "\n",
        "            ans_encoding =tokenizer.__call__(\n",
        "                ans_batch,\n",
        "                truncation=True,\n",
        "                max_length=ans_max_length,\n",
        "                padding='longest',\n",
        "                return_tensors = 'pt'\n",
        "            )\n",
        "            \n",
        "            out1,out2 = model(\n",
        "                    ques_encoding[\"input_ids\"].to(device),\n",
        "                    ques_encoding[\"attention_mask\"].to(device),\n",
        "                    ans_encoding[\"input_ids\"].to(device),\n",
        "                    ans_encoding[\"attention_mask\"].to(device)\n",
        "                )\n",
        "            \n",
        "            loss,correct_count = loss_fn(out1,out2)\n",
        "            losses.append(loss.item())\n",
        "            accuracy.append(correct_count/batch_size)\n",
        "\n",
        "    model.train()\n",
        "    return np.mean(losses), np.mean(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJjOe-sC5QVs"
      },
      "outputs": [],
      "source": [
        "def train_epoch( model, data_loader, loss_fn, optimizer,scheduler,epoch):\n",
        "    global best_loss\n",
        "    model.train()\n",
        "    losses = []\n",
        "    accuracy = []\n",
        "\n",
        "    for i, batch in enumerate(data_loader):\n",
        "        #tokenize\n",
        "\n",
        "        ques_title_batch, ques_body_batch, ans_batch = batch[\"ques_title\"], batch['ques_body'], batch[\"ans\"]      \n",
        "        ques_encoding =tokenizer.__call__(\n",
        "            ques_title_batch,\n",
        "            text_pair = ques_body_batch,\n",
        "            truncation=True,\n",
        "            max_length=ques_max_length,\n",
        "            padding='longest',\n",
        "            return_tensors = 'pt'\n",
        "        )  \n",
        "\n",
        "        ans_encoding =tokenizer.__call__(\n",
        "            ans_batch,\n",
        "            truncation=True,\n",
        "            max_length=ans_max_length,\n",
        "            padding='longest',\n",
        "            return_tensors = 'pt'\n",
        "        )\n",
        "        #forward\n",
        "        out1,out2 = model(\n",
        "                ques_encoding[\"input_ids\"].to(device),\n",
        "                ques_encoding[\"attention_mask\"].to(device),\n",
        "                ans_encoding[\"input_ids\"].to(device),\n",
        "                ans_encoding[\"attention_mask\"].to(device)\n",
        "            )\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss,correct_count = loss_fn(out1,out2)\n",
        "        losses.append(loss.item())\n",
        "        accuracy.append(correct_count/batch_size)\n",
        "        history[\"batch_loss\"].append(loss.item())\n",
        "        history[\"batch_acc\"].append(correct_count/batch_size)\n",
        "\n",
        "        #backward\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        #save\n",
        "        if (i+1)%2000==0:\n",
        "            save_recent(model,history,best_loss)\n",
        "            l = np.mean(losses)\n",
        "            acc =  np.mean(accuracy)\n",
        "            print(f'Epoch [{epoch+1}/{num_train_epochs}], Step [{i+1}/{len(data_loader)}], Small Step Train Loss:{l:.4f}, Train Accuracy:{acc*100:.4f}%')\n",
        "            print( \"-\" * 20)\n",
        "\n",
        "        if (i+1)%10000==0 or i+1 == len(data_loader):\n",
        "            l = np.mean(losses)\n",
        "            acc =  np.mean(accuracy)\n",
        "            val_loss,val_acc = eval_model(model,val_data_loader,loss_fn)\n",
        "\n",
        "            history['train_loss'].append(l)\n",
        "            history['train_acc'].append(acc)\n",
        "\n",
        "            history['val_acc'].append(val_acc)\n",
        "            history['val_loss'].append(val_loss)\n",
        "\n",
        "            print(f'Epoch [{epoch+1}/{num_train_epochs}], Step [{i+1}/{len(data_loader)}], Big Step Train Loss:{l:.4f}, Validation Loss:{val_loss:.4f}')\n",
        "            print(f'Epoch [{epoch+1}/{num_train_epochs}], Step [{i+1}/{len(data_loader)}], Big Step Train Accuracy:{acc*100:.4f}%, Validation Accuracy:{val_acc*100:.4f}%')\n",
        "            print( \"-\" * 20)\n",
        "\n",
        "            #save best model weight (based on validation)\n",
        "            if val_loss < best_loss:\n",
        "                save_best(model)\n",
        "                best_loss = val_loss\n",
        "            save_recent(model,history,best_loss)\n",
        "\n",
        "    return np.mean(losses), np.mean(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qH2vuzHdwgwk",
        "outputId": "c8ce8a98-701b-463b-c0a8-b069ee7354d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved at 16:15:21\n",
            "Epoch [1/4], Step [2000/50584], Small Step Train Loss:0.9915, Train Accuracy:77.8563%\n",
            "--------------------\n",
            "Saved at 16:29:23\n",
            "Epoch [1/4], Step [4000/50584], Small Step Train Loss:0.6658, Train Accuracy:83.8172%\n",
            "--------------------\n",
            "Saved at 16:43:24\n",
            "Epoch [1/4], Step [6000/50584], Small Step Train Loss:0.5426, Train Accuracy:86.1854%\n",
            "--------------------\n",
            "Saved at 16:57:26\n",
            "Epoch [1/4], Step [8000/50584], Small Step Train Loss:0.4747, Train Accuracy:87.6281%\n",
            "--------------------\n",
            "Saved at 17:11:27\n",
            "Epoch [1/4], Step [10000/50584], Small Step Train Loss:0.4305, Train Accuracy:88.6131%\n",
            "--------------------\n",
            "Epoch [1/4], Step [10000/50584], Big Step Train Loss:0.4305, Validation Loss:0.1969\n",
            "Epoch [1/4], Step [10000/50584], Big Step Train Accuracy:88.6131%, Validation Accuracy:93.8959%\n",
            "--------------------\n",
            "Saved at 17:13:23\n",
            "Saved at 17:27:25\n",
            "Epoch [1/4], Step [12000/50584], Small Step Train Loss:0.3980, Train Accuracy:89.3687%\n",
            "--------------------\n",
            "Saved at 17:41:26\n",
            "Epoch [1/4], Step [14000/50584], Small Step Train Loss:0.3731, Train Accuracy:89.9701%\n",
            "--------------------\n",
            "Saved at 17:55:28\n",
            "Epoch [1/4], Step [16000/50584], Small Step Train Loss:0.3532, Train Accuracy:90.4527%\n",
            "--------------------\n",
            "Saved at 18:09:32\n",
            "Epoch [1/4], Step [18000/50584], Small Step Train Loss:0.3372, Train Accuracy:90.8486%\n",
            "--------------------\n",
            "Saved at 18:23:35\n",
            "Epoch [1/4], Step [20000/50584], Small Step Train Loss:0.3240, Train Accuracy:91.1747%\n",
            "--------------------\n",
            "Epoch [1/4], Step [20000/50584], Big Step Train Loss:0.3240, Validation Loss:0.1593\n",
            "Epoch [1/4], Step [20000/50584], Big Step Train Accuracy:91.1747%, Validation Accuracy:95.2335%\n",
            "--------------------\n",
            "Saved at 18:25:32\n",
            "Saved at 18:39:35\n",
            "Epoch [1/4], Step [22000/50584], Small Step Train Loss:0.3126, Train Accuracy:91.4759%\n",
            "--------------------\n",
            "Saved at 18:53:37\n",
            "Epoch [1/4], Step [24000/50584], Small Step Train Loss:0.3027, Train Accuracy:91.7326%\n",
            "--------------------\n",
            "Saved at 19:07:39\n",
            "Epoch [1/4], Step [26000/50584], Small Step Train Loss:0.2941, Train Accuracy:91.9599%\n",
            "--------------------\n",
            "Saved at 19:21:42\n",
            "Epoch [1/4], Step [28000/50584], Small Step Train Loss:0.2863, Train Accuracy:92.1614%\n",
            "--------------------\n",
            "Saved at 19:35:42\n",
            "Epoch [1/4], Step [30000/50584], Small Step Train Loss:0.2789, Train Accuracy:92.3521%\n",
            "--------------------\n",
            "Epoch [1/4], Step [30000/50584], Big Step Train Loss:0.2789, Validation Loss:0.1632\n",
            "Epoch [1/4], Step [30000/50584], Big Step Train Accuracy:92.3521%, Validation Accuracy:95.7928%\n",
            "--------------------\n",
            "Saved at 19:37:36\n",
            "Saved at 19:51:36\n",
            "Epoch [1/4], Step [32000/50584], Small Step Train Loss:0.2727, Train Accuracy:92.5246%\n",
            "--------------------\n",
            "Saved at 20:05:34\n",
            "Epoch [1/4], Step [34000/50584], Small Step Train Loss:0.2670, Train Accuracy:92.6798%\n",
            "--------------------\n",
            "Saved at 20:19:33\n",
            "Epoch [1/4], Step [36000/50584], Small Step Train Loss:0.2615, Train Accuracy:92.8257%\n",
            "--------------------\n",
            "Saved at 20:33:32\n",
            "Epoch [1/4], Step [38000/50584], Small Step Train Loss:0.2568, Train Accuracy:92.9503%\n",
            "--------------------\n",
            "Saved at 20:47:32\n",
            "Epoch [1/4], Step [40000/50584], Small Step Train Loss:0.2522, Train Accuracy:93.0758%\n",
            "--------------------\n",
            "Epoch [1/4], Step [40000/50584], Big Step Train Loss:0.2522, Validation Loss:0.1410\n",
            "Epoch [1/4], Step [40000/50584], Big Step Train Accuracy:93.0758%, Validation Accuracy:95.9549%\n",
            "--------------------\n",
            "Saved at 20:49:28\n",
            "Saved at 21:03:28\n",
            "Epoch [1/4], Step [42000/50584], Small Step Train Loss:0.2479, Train Accuracy:93.1973%\n",
            "--------------------\n",
            "Saved at 21:17:26\n",
            "Epoch [1/4], Step [44000/50584], Small Step Train Loss:0.2436, Train Accuracy:93.3195%\n",
            "--------------------\n",
            "Saved at 21:31:24\n",
            "Epoch [1/4], Step [46000/50584], Small Step Train Loss:0.2398, Train Accuracy:93.4219%\n",
            "--------------------\n",
            "Saved at 21:45:23\n",
            "Epoch [1/4], Step [48000/50584], Small Step Train Loss:0.2361, Train Accuracy:93.5221%\n",
            "--------------------\n",
            "Saved at 21:59:22\n",
            "Epoch [1/4], Step [50000/50584], Small Step Train Loss:0.2327, Train Accuracy:93.6125%\n",
            "--------------------\n",
            "Epoch [1/4], Step [50000/50584], Big Step Train Loss:0.2327, Validation Loss:0.1302\n",
            "Epoch [1/4], Step [50000/50584], Big Step Train Accuracy:93.6125%, Validation Accuracy:96.4737%\n",
            "--------------------\n",
            "Saved at 22:01:19\n",
            "Epoch [1/4], Step [50584/50584], Big Step Train Loss:0.2317, Validation Loss:0.1199\n",
            "Epoch [1/4], Step [50584/50584], Big Step Train Accuracy:93.6394%, Validation Accuracy:96.6359%\n",
            "--------------------\n",
            "Saved at 22:07:19\n",
            "Saved at 22:21:17\n",
            "Epoch [2/4], Step [2000/50584], Small Step Train Loss:0.1221, Train Accuracy:96.8875%\n",
            "--------------------\n",
            "Saved at 22:35:16\n",
            "Epoch [2/4], Step [4000/50584], Small Step Train Loss:0.1245, Train Accuracy:96.7766%\n",
            "--------------------\n",
            "Saved at 22:49:15\n",
            "Epoch [2/4], Step [6000/50584], Small Step Train Loss:0.1232, Train Accuracy:96.8312%\n",
            "--------------------\n",
            "Saved at 23:03:14\n",
            "Epoch [2/4], Step [8000/50584], Small Step Train Loss:0.1234, Train Accuracy:96.8195%\n",
            "--------------------\n",
            "Saved at 23:17:12\n",
            "Epoch [2/4], Step [10000/50584], Small Step Train Loss:0.1236, Train Accuracy:96.8069%\n",
            "--------------------\n",
            "Epoch [2/4], Step [10000/50584], Big Step Train Loss:0.1236, Validation Loss:0.1261\n",
            "Epoch [2/4], Step [10000/50584], Big Step Train Accuracy:96.8069%, Validation Accuracy:96.7980%\n",
            "--------------------\n",
            "Saved at 23:19:06\n",
            "Saved at 23:33:04\n",
            "Epoch [2/4], Step [12000/50584], Small Step Train Loss:0.1227, Train Accuracy:96.8031%\n",
            "--------------------\n",
            "Saved at 23:47:03\n",
            "Epoch [2/4], Step [14000/50584], Small Step Train Loss:0.1227, Train Accuracy:96.8067%\n",
            "--------------------\n",
            "Saved at 00:01:02\n",
            "Epoch [2/4], Step [16000/50584], Small Step Train Loss:0.1225, Train Accuracy:96.8121%\n",
            "--------------------\n",
            "Saved at 00:15:01\n",
            "Epoch [2/4], Step [18000/50584], Small Step Train Loss:0.1220, Train Accuracy:96.8160%\n",
            "--------------------\n",
            "Saved at 00:29:01\n",
            "Epoch [2/4], Step [20000/50584], Small Step Train Loss:0.1218, Train Accuracy:96.8341%\n",
            "--------------------\n",
            "Epoch [2/4], Step [20000/50584], Big Step Train Loss:0.1218, Validation Loss:0.1296\n",
            "Epoch [2/4], Step [20000/50584], Big Step Train Accuracy:96.8341%, Validation Accuracy:96.8709%\n",
            "--------------------\n",
            "Saved at 00:30:55\n",
            "Saved at 00:44:54\n",
            "Epoch [2/4], Step [22000/50584], Small Step Train Loss:0.1213, Train Accuracy:96.8509%\n",
            "--------------------\n",
            "Saved at 00:58:54\n",
            "Epoch [2/4], Step [24000/50584], Small Step Train Loss:0.1210, Train Accuracy:96.8654%\n",
            "--------------------\n",
            "Saved at 01:12:53\n",
            "Epoch [2/4], Step [26000/50584], Small Step Train Loss:0.1205, Train Accuracy:96.8861%\n",
            "--------------------\n",
            "Saved at 01:26:53\n",
            "Epoch [2/4], Step [28000/50584], Small Step Train Loss:0.1198, Train Accuracy:96.9065%\n",
            "--------------------\n",
            "Saved at 01:40:51\n",
            "Epoch [2/4], Step [30000/50584], Small Step Train Loss:0.1187, Train Accuracy:96.9398%\n",
            "--------------------\n",
            "Epoch [2/4], Step [30000/50584], Big Step Train Loss:0.1187, Validation Loss:0.1442\n",
            "Epoch [2/4], Step [30000/50584], Big Step Train Accuracy:96.9398%, Validation Accuracy:96.9439%\n",
            "--------------------\n",
            "Saved at 01:42:46\n",
            "Saved at 01:56:45\n",
            "Epoch [2/4], Step [32000/50584], Small Step Train Loss:0.1185, Train Accuracy:96.9516%\n",
            "--------------------\n",
            "Saved at 02:10:45\n",
            "Epoch [2/4], Step [34000/50584], Small Step Train Loss:0.1181, Train Accuracy:96.9719%\n",
            "--------------------\n",
            "Saved at 02:24:47\n",
            "Epoch [2/4], Step [36000/50584], Small Step Train Loss:0.1176, Train Accuracy:96.9858%\n",
            "--------------------\n",
            "Saved at 02:38:49\n",
            "Epoch [2/4], Step [38000/50584], Small Step Train Loss:0.1169, Train Accuracy:97.0010%\n",
            "--------------------\n",
            "Saved at 02:52:51\n",
            "Epoch [2/4], Step [40000/50584], Small Step Train Loss:0.1165, Train Accuracy:97.0120%\n",
            "--------------------\n",
            "Epoch [2/4], Step [40000/50584], Big Step Train Loss:0.1165, Validation Loss:0.1122\n",
            "Epoch [2/4], Step [40000/50584], Big Step Train Accuracy:97.0120%, Validation Accuracy:97.1952%\n",
            "--------------------\n",
            "Saved at 02:54:49\n",
            "Saved at 03:08:52\n",
            "Epoch [2/4], Step [42000/50584], Small Step Train Loss:0.1159, Train Accuracy:97.0214%\n",
            "--------------------\n",
            "Saved at 03:22:53\n",
            "Epoch [2/4], Step [44000/50584], Small Step Train Loss:0.1156, Train Accuracy:97.0334%\n",
            "--------------------\n",
            "Saved at 03:36:52\n",
            "Epoch [2/4], Step [46000/50584], Small Step Train Loss:0.1152, Train Accuracy:97.0404%\n",
            "--------------------\n",
            "Saved at 03:50:54\n",
            "Epoch [2/4], Step [48000/50584], Small Step Train Loss:0.1150, Train Accuracy:97.0477%\n",
            "--------------------\n",
            "Saved at 04:04:53\n",
            "Epoch [2/4], Step [50000/50584], Small Step Train Loss:0.1146, Train Accuracy:97.0607%\n",
            "--------------------\n",
            "Epoch [2/4], Step [50000/50584], Big Step Train Loss:0.1146, Validation Loss:0.1083\n",
            "Epoch [2/4], Step [50000/50584], Big Step Train Accuracy:97.0607%, Validation Accuracy:97.2357%\n",
            "--------------------\n",
            "Saved at 04:06:50\n",
            "Epoch [2/4], Step [50584/50584], Big Step Train Loss:0.1145, Validation Loss:0.1145\n",
            "Epoch [2/4], Step [50584/50584], Big Step Train Accuracy:97.0644%, Validation Accuracy:97.3898%\n",
            "--------------------\n",
            "Saved at 04:12:49\n",
            "Saved at 04:26:47\n",
            "Epoch [3/4], Step [2000/50584], Small Step Train Loss:0.0822, Train Accuracy:97.9781%\n",
            "--------------------\n",
            "Saved at 04:40:49\n",
            "Epoch [3/4], Step [4000/50584], Small Step Train Loss:0.0824, Train Accuracy:97.9797%\n",
            "--------------------\n",
            "Saved at 04:54:52\n",
            "Epoch [3/4], Step [6000/50584], Small Step Train Loss:0.0837, Train Accuracy:97.9688%\n",
            "--------------------\n",
            "Saved at 05:08:55\n",
            "Epoch [3/4], Step [8000/50584], Small Step Train Loss:0.0837, Train Accuracy:97.9531%\n",
            "--------------------\n",
            "Saved at 05:22:56\n",
            "Epoch [3/4], Step [10000/50584], Small Step Train Loss:0.0836, Train Accuracy:97.9363%\n",
            "--------------------\n",
            "Epoch [3/4], Step [10000/50584], Big Step Train Loss:0.0836, Validation Loss:0.1155\n",
            "Epoch [3/4], Step [10000/50584], Big Step Train Accuracy:97.9363%, Validation Accuracy:97.4141%\n",
            "--------------------\n",
            "Saved at 05:24:50\n",
            "Saved at 05:38:48\n",
            "Epoch [3/4], Step [12000/50584], Small Step Train Loss:0.0831, Train Accuracy:97.9354%\n",
            "--------------------\n",
            "Saved at 05:52:47\n",
            "Epoch [3/4], Step [14000/50584], Small Step Train Loss:0.0833, Train Accuracy:97.9339%\n",
            "--------------------\n",
            "Saved at 06:06:45\n",
            "Epoch [3/4], Step [16000/50584], Small Step Train Loss:0.0831, Train Accuracy:97.9473%\n",
            "--------------------\n",
            "Saved at 06:20:44\n",
            "Epoch [3/4], Step [18000/50584], Small Step Train Loss:0.0827, Train Accuracy:97.9635%\n",
            "--------------------\n",
            "Saved at 06:34:42\n",
            "Epoch [3/4], Step [20000/50584], Small Step Train Loss:0.0829, Train Accuracy:97.9741%\n",
            "--------------------\n",
            "Epoch [3/4], Step [20000/50584], Big Step Train Loss:0.0829, Validation Loss:0.1224\n",
            "Epoch [3/4], Step [20000/50584], Big Step Train Accuracy:97.9741%, Validation Accuracy:97.2195%\n",
            "--------------------\n",
            "Saved at 06:36:37\n",
            "Saved at 06:50:35\n",
            "Epoch [3/4], Step [22000/50584], Small Step Train Loss:0.0831, Train Accuracy:97.9702%\n",
            "--------------------\n",
            "Saved at 07:04:36\n",
            "Epoch [3/4], Step [24000/50584], Small Step Train Loss:0.0831, Train Accuracy:97.9708%\n",
            "--------------------\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-75016edb10ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnegative_log_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-a5c88ab0152c>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, loss_fn, optimizer, scheduler, epoch)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m#backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for epoch in range(num_train_epochs):\n",
        "    train_loss = train_epoch( model,train_data_loader,negative_log_loss, optimizer,scheduler, epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "X4VBKh8hVnLl",
        "outputId": "a349fbdd-0a50-44ab-f764-1cfa205b0b7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa3a4c82550>"
            ]
          },
          "execution_count": 26,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history[\"train_acc\"], label='train Accuracy')\n",
        "plt.plot(history[\"val_acc\"], label='validation Accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('validation step (4 per Epoch)')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "hIl3pm5hP-a7",
        "outputId": "f7168528-398e-465e-821a-42f9e5f1ce00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa3a3702f50>"
            ]
          },
          "execution_count": 27,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history[\"train_loss\"], label='train loss')\n",
        "plt.plot(history[\"val_loss\"], label='validation loss')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('validation step (4 per Epoch)')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilqE9R31YuSP",
        "outputId": "9226a418-7f16-4ded-ee54-366c6255f416"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "197216"
            ]
          },
          "execution_count": 36,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_tjZNd2XrLJ"
      },
      "outputs": [],
      "source": [
        "test_loss,test_acc =eval_model(model,test_data_loader,negative_log_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deXvKOLVbOnw",
        "outputId": "8899eb42-edd2-469d-db33-fb45d82506a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test Accuracy is 97.54150702426566%\n"
          ]
        }
      ],
      "source": [
        "print(f\"test Accuracy is {test_acc*100}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6xMgwL3bX8U",
        "outputId": "bb645114-67e8-46c7-cdf9-f9fadac1b655"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test Loss is 0.11394203385568819\n"
          ]
        }
      ],
      "source": [
        "print(f\"test Loss is {test_loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8kV7TagDur6"
      },
      "source": [
        "fasl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZDQoeJd9Qtr"
      },
      "outputs": [],
      "source": [
        "test = test_dataset[:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6G62CBOl9Ywe",
        "outputId": "92d3a90b-b02c-4980-d9af-621a34a811c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12513, 768)\n",
            "[[ 0.21957041  0.05871633 -0.47717711 ... -0.02059981 -0.26361862\n",
            "  -0.1701171 ]\n",
            " [ 0.07024603  0.3239693  -0.05192249 ...  0.15993565 -0.27529338\n",
            "   0.27964827]\n",
            " [ 0.26350206  0.29723573  0.06827255 ...  0.05135059 -0.04910861\n",
            "   0.10554145]\n",
            " ...\n",
            " [ 0.2703141   0.44326222 -0.34210336 ...  0.04567766  0.25472993\n",
            "  -0.33304831]\n",
            " [ 0.18905362  0.01253811 -0.2969546  ... -0.04815906  0.00241213\n",
            "  -0.20985492]\n",
            " [ 0.13487095 -0.02454663 -0.46219724 ... -0.55548501  0.18564965\n",
            "  -0.09016064]]\n"
          ]
        }
      ],
      "source": [
        "test_encoding = np.empty((0,768))\n",
        "ques_encoder_model.eval()\n",
        "with torch.no_grad():\n",
        "    for x in test.iterrows():\n",
        "        ques_title,ques_body = x[1][\"ques_title\"],x[1][\"ques_body\"]\n",
        "        ques_encoding =tokenizer.__call__(\n",
        "            ques_title,\n",
        "            text_pair = ques_body,\n",
        "            truncation=True,\n",
        "            max_length=ques_max_length,\n",
        "            padding='longest',\n",
        "            return_tensors = 'pt'\n",
        "        )\n",
        "        enc = ques_encoder_model( ques_encoding[\"input_ids\"].to(device), ques_encoding[\"attention_mask\"].to(device))\n",
        "        test_encoding = np.vstack([test_encoding,enc.cpu()])\n",
        "print(test_encoding.shape)\n",
        "print(test_encoding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_PBknmHEhjR"
      },
      "outputs": [],
      "source": [
        "ans_encoding = np.empty((0,768))\n",
        "ans_encoder_model.eval()\n",
        "with torch.no_grad():\n",
        "    for i,x in enumerate( test_dataset[\"ans\"]):\n",
        "            \n",
        "        ans_enc =tokenizer.__call__(\n",
        "            x,\n",
        "            truncation=True,\n",
        "            max_length=ans_max_length,\n",
        "            padding='longest',\n",
        "            return_tensors = 'pt'\n",
        "        )\n",
        "        ans_enc = ans_encoder_model( ans_enc[\"input_ids\"].to(device), ans_enc[\"attention_mask\"].to(device))\n",
        "        ans_encoding = np.vstack([ans_encoding,ans_enc.cpu()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ng2ujIWJgTo",
        "outputId": "fc00af1e-2288-4468-cd3f-7a673c6a1845"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of questions 12513\n",
            "number of answers available 12513\n"
          ]
        }
      ],
      "source": [
        "print(\"number of questions\",len(test_encoding))\n",
        "print(\"number of answers available\",len(ans_encoding))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jicPXll2NXtJ"
      },
      "outputs": [],
      "source": [
        "def eval_top_k(test_encoding,ans_encoding,k):\n",
        "    similarity = np.dot(test_encoding,ans_encoding.T)\n",
        "    pred = np.argpartition(-similarity, k)[:,:k]\n",
        "    cnt =0 \n",
        "    for i,row in enumerate(pred):\n",
        "        if i in row:\n",
        "            cnt+=1\n",
        "    return cnt/len(test_encoding)*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2QZ-X74Fbgz",
        "outputId": "80f9f237-5760-42b9-88c4-73240dc62a45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "percantage of exact matches: 53.84%\n"
          ]
        }
      ],
      "source": [
        "k=1\n",
        "print(f\"percantage of exact matches: {eval_top_k(test_encoding,ans_encoding,k):.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urCe88nUKpnV",
        "outputId": "c8648a81-aa0f-48e2-830f-d314d1e2c7af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "percantage of Top-5 retrieved answers matches: 73.36%\n"
          ]
        }
      ],
      "source": [
        "k=5\n",
        "print(f\"percantage of Top-5 retrieved answers matches: {eval_top_k(test_encoding,ans_encoding,k):.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPWxb6KhLAbV",
        "outputId": "31ac98cf-4245-4bda-ba7b-a782eaf27be7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "percantage of Top-10 retrieved answers matches: 79.83%\n"
          ]
        }
      ],
      "source": [
        "k=10\n",
        "print(f\"percantage of Top-10 retrieved answers matches: {eval_top_k(test_encoding,ans_encoding,k):.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIgxeSnOLCaq",
        "outputId": "53ad4ccd-b4fc-42ea-b33d-f17c727a0635"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "percantage of Top-100 retrieved answers matches: 94.57%\n"
          ]
        }
      ],
      "source": [
        "k=100\n",
        "print(f\"percantage of Top-100 retrieved answers matches: {eval_top_k(test_encoding,ans_encoding,k):.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "final_dot.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e731b6f773e435fa68f71f0a5b13f92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a91a2d21aabc4b44b02dbdeecaa81672",
              "IPY_MODEL_f3800d9af1a6447cac954cdc0b270951"
            ],
            "layout": "IPY_MODEL_575ac7fb8c794006a9afc34867ece5f4"
          },
          "model_module_version": "1.5.0"
        },
        "575ac7fb8c794006a9afc34867ece5f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          },
          "model_module_version": "1.2.0"
        },
        "7003e0810c2147ca9c7a3fbf4fa58594": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          },
          "model_module_version": "1.2.0"
        },
        "789bcaec8ddb44d3b5bb32d92b6363f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          },
          "model_module_version": "1.5.0"
        },
        "a91a2d21aabc4b44b02dbdeecaa81672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7003e0810c2147ca9c7a3fbf4fa58594",
            "max": 267967963,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc18683023bf4c089c9274f0874d826b",
            "value": 267967963
          },
          "model_module_version": "1.5.0"
        },
        "cc18683023bf4c089c9274f0874d826b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          },
          "model_module_version": "1.5.0"
        },
        "df737e446eee4f9faaed72f1d0975385": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          },
          "model_module_version": "1.2.0"
        },
        "f3800d9af1a6447cac954cdc0b270951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df737e446eee4f9faaed72f1d0975385",
            "placeholder": "​",
            "style": "IPY_MODEL_789bcaec8ddb44d3b5bb32d92b6363f1",
            "value": " 268M/268M [00:05&lt;00:00, 48.8MB/s]"
          },
          "model_module_version": "1.5.0"
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}